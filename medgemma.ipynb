{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8392208-f730-4554-b7ae-6fd7a67bb3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import re\n",
    "import glob\n",
    "from PIL import Image\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "\n",
    "# CONFIGURATION\n",
    "MODEL_ID = \"google/medgemma-4b-it\"\n",
    "\n",
    "OUTPUT_FILE = \"./results_marisse.csv\"\n",
    "IMAGE_PATH = \"./full-fundus/*.*\"\n",
    "\n",
    "# INITIALIZE PIPELINE\n",
    "pipe = pipeline(\n",
    "    \"image-text-to-text\",\n",
    "    model=MODEL_ID,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # device_map=\"auto\",\n",
    "    device=1,\n",
    ")\n",
    "\n",
    "# PROMPT\n",
    "base_prompt_text = (\n",
    "    \"You are an expert ophthalmologist. Evaluate this fundus image for signs of glaucoma \"\n",
    "    \"(optic disc cupping, RNFL loss, peripapillary atrophy). \"\n",
    "    \"Write your Key Findings. Then provide your Conclusion. Do not include a Disclaimer.\"\n",
    ")\n",
    "\n",
    "# LOAD IMAGES\n",
    "image_files = sorted(glob.glob(IMAGE_PATH))\n",
    "print(f\"Found {len(image_files)} images.\")\n",
    "\n",
    "# Ensure directory exists\n",
    "os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)\n",
    "\n",
    "# PROCESSING LOOP\n",
    "with open(OUTPUT_FILE, mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"Image File\", \"Full Reasoning\"])\n",
    "\n",
    "    for image_file in tqdm(image_files):\n",
    "        try:\n",
    "            image = Image.open(image_file).convert(\"RGB\")  # Ensure consistent color channels\n",
    "\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": base_prompt_text},\n",
    "                        {\"type\": \"image\", \"image\": image}\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "\n",
    "            output = pipe(\n",
    "                messages,\n",
    "                max_new_tokens=2048,\n",
    "                do_sample=False\n",
    "            )\n",
    "\n",
    "            generated_text = output[0][\"generated_text\"]\n",
    "            if isinstance(generated_text, list):\n",
    "                raw_response = generated_text[-1][\"content\"].strip()\n",
    "            else:\n",
    "                raw_response = generated_text.strip()\n",
    "\n",
    "            writer.writerow([os.path.basename(image_file), raw_response])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_file}: {e}\")\n",
    "            writer.writerow([os.path.basename(image_file), \"ERROR\", str(e)])\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medgemma",
   "language": "python",
   "name": "medgemma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
